{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d55062-c337-4d7a-a1bf-357c21bdc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import scipy.ndimage\n",
    "from scipy import misc\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import skimage\n",
    "import imageio\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4b983-fc9f-4377-8793-5e498e649f53",
   "metadata": {},
   "source": [
    "Pre-processing the dataset\n",
    "Before we load the data we need to alter the dataset structure. When you download the dataset, all the images are together in a folder. To use Pytorch dataloader we need to seggregrate the images into folders of their respetive labels. You can use the following script to automate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e060c71-9cdd-4649-8a0c-c3a2a9bed84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import shutil\n",
    "\n",
    "data_dir = os.getcwd() + \"/data/HAM10000_imgs\" \n",
    "dest_dir = os.getcwd() + \"/data/HAM10000\" + \"test/\" #had to change this\n",
    "metadata = pd.read_csv(os.getcwd() + \"/data/HAM10000\" + '/HAM10000_metadata') #got rid of the .csv extension\n",
    "\n",
    "label = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n",
    "label_images = []\n",
    "\n",
    "for i in label:\n",
    "    os.mkdir(dest_dir + str(i) + '/')\n",
    "    sample = metadata[metadata['dx'] == i]['image_id']#[:5] not sure why this is here? only gets 5 images?\n",
    "    label_images.extend(sample)\n",
    "    for id in label_images:\n",
    "        shutil.copyfile((data_dir + \"/\"+ id +\".jpg\"), (dest_dir + \"/\" + i + \"/\"+id+\".jpg\")) #had to change this string to work\n",
    "    label_images=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd9a6d-1234-4eae-a2f8-f8adcd92eeba",
   "metadata": {},
   "source": [
    "Let's visualize some examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99509d92-8363-47de-936e-1dbf731c2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the images\n",
    "\n",
    "label = [ 'akiec', 'bcc','bkl','df','mel', 'nv',  'vasc']\n",
    "label_images = []\n",
    "classes = [ 'actinic keratoses', 'basal cell carcinoma', 'benign keratosis-like lesions', \n",
    "           'dermatofibroma','melanoma', 'melanocytic nevi', 'vascular lesions']\n",
    "\n",
    "data_dir = os.getcwd() + \"/data/HAM10000\" \n",
    "\n",
    "fig = plt.figure(figsize=(55, 55))\n",
    "k = range(7)\n",
    "\n",
    "for i in label:\n",
    "    sample = metadata[metadata['dx'] == i]['image_id'][:5]\n",
    "    label_images.extend(sample)\n",
    "    \n",
    "for position,ID in enumerate(label_images):\n",
    "    labl = metadata[metadata['image_id'] == ID]['dx']\n",
    "    im_sample = data_dir + \"test\" + \"/\" + labl.values[0] + f'/{ID}.jpg' #had to change this\n",
    "    im_sample = imageio.imread(im_sample)\n",
    "\n",
    "    plt.subplot(7,5,position+1)\n",
    "    plt.imshow(im_sample)\n",
    "    plt.axis('off')\n",
    "\n",
    "    if position%5 == 0:\n",
    "        title = int(position/5)\n",
    "        plt.title(classes[title], loc='left', size=50, weight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fd7a4-97a7-4ad8-9a7a-01d305b34f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a sense of what the distribution of each column looks like\n",
    "\n",
    "fig = plt.figure(figsize=(40,25))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "metadata['dx'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count', size=50)\n",
    "ax1.set_title('Cell Type', size = 50)\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "metadata['sex'].value_counts().plot(kind='bar', ax=ax2)\n",
    "ax2.set_ylabel('Count', size=50)\n",
    "ax2.set_title('Sex', size=50);\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "metadata['localization'].value_counts().plot(kind='bar')\n",
    "ax3.set_ylabel('Count', size=50)\n",
    "ax3.set_title('Localization', size=50)\n",
    "\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "sample_age = metadata[pd.notnull(metadata['age'])]\n",
    "sns.distplot(sample_age['age'], fit=stats.norm, color='red');\n",
    "ax4.set_title('Age', size = 50)\n",
    "ax4.set_xlabel('Year', size=50)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
